import os
import zipfile
import urllib.request
import random
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout

# URL do dataset e configuração de pastas
DATA_URL = (
    "https://download.microsoft.com/download/3/E/1/"
    "3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip"
)
EXTRACT_PATH = "cats_and_dogs"

# Função para baixar e extrair os dados
def download_and_extract_data(url, extract_path):
    zip_path = "dataset.zip"
    if not os.path.exists(extract_path):
        print("Baixando dataset...")
        urllib.request.urlretrieve(url, zip_path)
        print("Extraindo dataset...")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_path)
        os.remove(zip_path)
        print("Dataset preparado!")
    else:
        print("Dataset já está preparado.")

download_and_extract_data(DATA_URL, EXTRACT_PATH)

# Configuração do gerador de dados
base_dir = os.path.join(EXTRACT_PATH, "PetImages")
datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    validation_split=0.2  # 20% dos dados para validação
)

# Criar geradores de treino e validação
train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)

# Carregar o modelo VGG16 pré-treinado
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Congelar as camadas da base do modelo

# Construir o modelo com transferência de aprendizado
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Camada de saída para classificação binária
])

# Compilar o modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# Treinamento do modelo
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=10,
    verbose=1
)

# Função para plotar os resultados
def plot_training_history(history):
    plt.figure(figsize=(12, 4))
    # Loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Loss - Treino')
    plt.plot(history.history['val_loss'], label='Loss - Validação')
    plt.legend()
    plt.title('Loss durante o Treinamento')
    # Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Accuracy - Treino')
    plt.plot(history.history['val_accuracy'], label='Accuracy - Validação')
    plt.legend()
    plt.title('Accuracy durante o Treinamento')
    plt.show()

# Plotar histórico do treinamento
plot_training_history(history)

# Avaliação final no conjunto de validação
loss, accuracy = model.evaluate(validation_generator, verbose=0)
print(f"Loss final: {loss:.4f}")
print(f"Accuracy final: {accuracy:.4f}")
